We collect a sample by capturing a sequence of screenshots before and after a shot using the smallest time gap (50 ms). The average time gap between the beginning and the end screenshot is 10 seconds. That is, a sample contains around 200 screenshots.  
We apply our method to the whole sequence so that the method will keep tracking the objects through all of the screenshots, from the first until the last. The match between the initial objects in the first screenshot and the subsequent objects in the last screenshot will be saved as the ground truth for later evaluation. 
To automate this process, we run an angry-birds agent that always aims at a random pig on the first 21 poached-eggs levels. The agent starts to capture screenshots once a shot is made, and stops after 10 seconds. At each level, the agent records the screenshots of at most four shots.
Finally, we have around 80 samples. To evaluate the accuracy of the \"ground truth\", we run our method on 10 samples randomly picked from the 80. We determine the accuracy by manually labelling the initial objects and their correspondence in the end screenshot, and compare with the matching. 


The method can match most of the objects with less than five mismatches per sample. The method achieves real-time performance with an average of 35 ms per match. To show the suitability of our reasoning method ???

To illustrate the significant improvements over existing methods, we compare our method with an approach ($BASIC$) that matches by visual appearance and minimizes the centroid shift between initial and subsequent objects. The results are shown in Table \ref{empiResults}.
